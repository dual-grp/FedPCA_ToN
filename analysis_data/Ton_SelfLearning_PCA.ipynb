{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pathlib import Path\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from csv files\n",
    "file_path_train = os.path.join(os.path.abspath('..'), \"abnormal_detection_data/train/ton_train_normal_49.csv\")\n",
    "file_path_test_normal = os.path.join(os.path.abspath('..'), \"abnormal_detection_data/test/ton_test_normal_49.csv\")\n",
    "file_path_test_abnormal = os.path.join(os.path.abspath('..'), \"abnormal_detection_data/test/ton_test_abnormal_49.csv\")\n",
    "df_train = pd.read_csv(file_path_train, index_col = 0)\n",
    "df_test_normal = pd.read_csv(file_path_test_normal, index_col = 0)\n",
    "df_test_abnormal = pd.read_csv(file_path_test_abnormal, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_normal = df_test_normal[:10000]\n",
    "df_test = pd.concat([df_test_normal, df_test_abnormal])\n",
    "df_test.columns = df_test_abnormal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56557, 49), (10000, 49))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_abnormal.shape, df_test_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the score function for abnormal detection\n",
    "def anomalyScores(originalDF, reducedDF):\n",
    "  loss = np.sum((np.array(originalDF)-np.array(reducedDF))**2, axis=1)\n",
    "  loss = pd.Series(data=loss,index=originalDF.index)\n",
    "  loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def results_analysis(df_gt_score, threshold, log=0):\n",
    "  df_gt_pred = pd.DataFrame()\n",
    "  df_gt_pred['ground_true'] = df_gt_score['ground_true']\n",
    "  index = df_gt_score['anomalyScore'] > threshold\n",
    "  df_gt_pred['prediction'] = index.astype(int)\n",
    "\n",
    "  TN, FP, FN, TP = confusion_matrix(df_gt_pred['ground_true'], df_gt_pred['prediction']).ravel()\n",
    "  precision_score = TP/(FP + TP)\n",
    "  recall_score = TP/(FN + TP)\n",
    "  accuracy_score = (TP + TN)/ (TP + FN + TN + FP)\n",
    "  f1_score = 2*precision_score*recall_score/(precision_score + recall_score)\n",
    "  fpr = FP / (FP+TN)\n",
    "  fng = FN / (TP+FN)\n",
    "\n",
    "  if log:\n",
    "    print(f\"Precision: {np.round(precision_score * 100.0,4)}%\")\n",
    "    print(f\"Recall: {np.round(recall_score * 100.0,4)}%\")\n",
    "    print(f\"Accuracy score: {np.round(accuracy_score * 100.0,4)}%\")\n",
    "    print(f\"F1 score: {np.round(f1_score * 100.0,4)}%\")\n",
    "    print(f\"False alarm: {np.round(fpr * 100.0,4)}%\")\n",
    "    print(f\"False Negative: {np.round(fng * 100.0,4)}%\")\n",
    "\n",
    "  return precision_score, recall_score, accuracy_score, f1_score, fpr, fng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "scaler = StandardScaler()\n",
    "def perform_pca(df_train, df_test):\n",
    "  pca = PCA(0.99)\n",
    "  pca.fit(scaler.transform(df_train))\n",
    "  df_test_PCA = pca.transform(df_test)\n",
    "  df_test_PCA_inverse = pca.inverse_transform(df_test_PCA)\n",
    "  df_test_PCA = pd.DataFrame(df_test_PCA)\n",
    "  df_test_PCA_inverse = pd.DataFrame(df_test_PCA_inverse)\n",
    "  return df_test_PCA, df_test_PCA_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on different number of clients for self-learning PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_raw = df_test.copy()\n",
    "df_normal_train = df_train.copy()\n",
    "df_normal_train = df_normal_train.sort_values(by=['src_port'])\n",
    "df_normal_train = df_normal_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Average results for 10 users--------------------\n",
      "Precision: 86.7952%\n",
      "Recall: 51.0701%\n",
      "Accuracy score: 51.8193%\n",
      "F1 score: 64.3039%\n",
      "False alarm: 43.943%\n",
      "False Negative: 48.9299%\n",
      "--------------------Average results for 20 users--------------------\n",
      "Precision: 88.8434%\n",
      "Recall: 52.2752%\n",
      "Accuracy score: 53.8675%\n",
      "F1 score: 65.8213%\n",
      "False alarm: 37.127%\n",
      "False Negative: 47.7248%\n",
      "--------------------Average results for 30 users--------------------\n",
      "Precision: 89.5172%\n",
      "Recall: 52.6717%\n",
      "Accuracy score: 54.5413%\n",
      "F1 score: 66.3206%\n",
      "False alarm: 34.8847%\n",
      "False Negative: 47.3283%\n",
      "--------------------Average results for 40 users--------------------\n",
      "Precision: 89.057%\n",
      "Recall: 52.4009%\n",
      "Accuracy score: 54.0812%\n",
      "F1 score: 65.9796%\n",
      "False alarm: 36.416%\n",
      "False Negative: 47.5991%\n",
      "--------------------Average results for 50 users--------------------\n",
      "Precision: 89.0789%\n",
      "Recall: 52.4138%\n",
      "Accuracy score: 54.103%\n",
      "F1 score: 65.9958%\n",
      "False alarm: 36.3432%\n",
      "False Negative: 47.5862%\n",
      "--------------------Average results for 60 users--------------------\n",
      "Precision: 88.4555%\n",
      "Recall: 52.047%\n",
      "Accuracy score: 53.4797%\n",
      "F1 score: 65.534%\n",
      "False alarm: 38.4177%\n",
      "False Negative: 47.953%\n",
      "--------------------Average results for 70 users--------------------\n",
      "Precision: 87.8616%\n",
      "Recall: 51.6975%\n",
      "Accuracy score: 52.8857%\n",
      "F1 score: 65.0939%\n",
      "False alarm: 40.3943%\n",
      "False Negative: 48.3025%\n",
      "--------------------Average results for 80 users--------------------\n",
      "Precision: 87.8689%\n",
      "Recall: 51.7019%\n",
      "Accuracy score: 52.8931%\n",
      "F1 score: 65.0994%\n",
      "False alarm: 40.3698%\n",
      "False Negative: 48.2981%\n",
      "--------------------Average results for 90 users--------------------\n",
      "Precision: 87.2271%\n",
      "Recall: 51.3242%\n",
      "Accuracy score: 52.2513%\n",
      "F1 score: 64.6239%\n",
      "False alarm: 42.5056%\n",
      "False Negative: 48.6758%\n",
      "--------------------Average results for 100 users--------------------\n",
      "Precision: 86.7877%\n",
      "Recall: 51.0657%\n",
      "Accuracy score: 51.8119%\n",
      "F1 score: 64.2983%\n",
      "False alarm: 43.9679%\n",
      "False Negative: 48.9343%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_experiments = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "for num_users in user_experiments:\n",
    "  fraction  = int(df_normal_train.shape[0] / num_users)\n",
    "  avg_acc = 0\n",
    "  avg_pre = 0\n",
    "  avg_rec = 0\n",
    "  avg_f1 = 0\n",
    "  avg_fpr = 0\n",
    "  avg_fng = 0\n",
    "  for i in range(num_users):\n",
    "    df_train_stdPCA = df_normal_train[fraction*i:fraction*(i+1)].copy()\n",
    "    df_train_client = df_train_stdPCA.copy()\n",
    "    # Standardization over Testing\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_train_client.to_numpy())\n",
    "    df_test = pd.DataFrame(scaler.transform(df_test_raw.to_numpy()))\n",
    "    df_test.columns = df_test_abnormal.columns\n",
    "    _, df_test_PCA_inverse = perform_pca(df_train_client.to_numpy(), df_test.to_numpy())\n",
    "\n",
    "    abnormal_score = anomalyScores(df_test, df_test_PCA_inverse)\n",
    "\n",
    "    df_gt_score_PCA = pd.DataFrame(); df_gt_pred_PCA = pd.DataFrame()\n",
    "    df_gt_score_PCA['ground_true'] = np.concatenate([np.zeros(len(df_test_normal)), np.ones(len(df_test_abnormal))])\n",
    "    df_gt_score_PCA['anomalyScore'] = abnormal_score\n",
    "\n",
    "    # choose the right threshold\n",
    "    lst_p = np.arange(1e-1,9e-1,1e-1) # Among test, ratio of normal/abnormal = 0.75\n",
    "    lst_rho = np.quantile(df_gt_score_PCA.anomalyScore, lst_p)\n",
    "    optimal_p = 5e-1\n",
    "    optimal_rho = lst_rho[abs(lst_p - optimal_p)<1e-8][0]\n",
    "    \n",
    "    precision_score, recall_score, accuracy_score, f1_score, fpr, fng = results_analysis(df_gt_score_PCA, threshold=optimal_rho, log=0)\n",
    "    avg_acc += accuracy_score\n",
    "    avg_pre += precision_score\n",
    "    avg_rec += recall_score\n",
    "    avg_f1 += f1_score\n",
    "    avg_fpr += fpr\n",
    "    avg_fng += fng\n",
    "  print(f\"--------------------Average results for {num_users} users--------------------\")\n",
    "  print(f\"Precision: {np.round(avg_pre * 100.0/num_users,4)}%\")\n",
    "  print(f\"Recall: {np.round(avg_rec * 100.0/num_users,4)}%\")\n",
    "  print(f\"Accuracy score: {np.round(avg_acc * 100.0/num_users,4)}%\")\n",
    "  print(f\"F1 score: {np.round(avg_f1 * 100.0/num_users,4)}%\")\n",
    "  print(f\"False alarm: {np.round(avg_fpr * 100.0/num_users,4)}%\")\n",
    "  print(f\"False Negative: {np.round(avg_fng * 100.0/num_users,4)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
